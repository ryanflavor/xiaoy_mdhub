# Story 3.3: "Hard Restart" Recovery Mechanism

## Status: Done

## Story

**As a** the system,
**I want** to automatically attempt to recover a failed gateway by performing a full process restart,
**so that** the system's redundancy can be restored without manual intervention.

## Acceptance Criteria (ACs)

1. **Cool-down Period**: After a gateway is marked `UNHEALTHY`, a configurable cool-down period is triggered.
2. **Process Termination**: After the cool-down, the `GatewayManager` is instructed to terminate the failed gateway's process.
3. **Process Relaunch**: The `GatewayManager` then relaunches a new, clean process for that gateway.
4. **Recovery Tracking**: The `HealthMonitor` tracks the recovery of the restarting gateway.

## Dev Technical Guidance

### Previous Story Insights
From Story 3.2, the Quote Aggregation Engine is complete with:
- **Automated Failover System**: Fully functional failover logic with event-driven gateway switching
- **Event Bus Integration**: Comprehensive health event subscription system for gateway status changes
- **Gateway Manager Extensions**: Contract migration capabilities with seamless subscription transfers
- **Performance Metrics**: Failover execution time tracking and resource usage monitoring
- **ZMQ Publishing Continuity**: Zero-interruption tick publishing during gateway switches

### Data Models
Based on existing architecture and recovery requirements:
- **MarketDataAccount**: Already defined with gateway configuration for restart operations [Source: architecture/05-4-data-models.md#4]
  - `id` field for unique gateway identification during restart
  - `gateway_type` for CTP/SOPT specific restart procedures
  - `settings` object containing connection parameters for clean process initialization
  - `is_enabled` boolean for controlling restart eligibility
- **Gateway Status Events**: From Story 3.1 event bus system for recovery status tracking
  - Event format: `{"event_type": "gateway_recovery_started", "gateway_id": "...", "restart_attempt": 1}`
  - Recovery status events: `gateway_recovery_completed`, `gateway_recovery_failed`
- **Recovery State Tracking**: Need to track restart attempts and cooldown periods
  - Current restart attempt count per gateway
  - Last restart timestamp for cooldown calculations
  - Recovery status per gateway (`COOLING_DOWN`, `RESTARTING`, `RECOVERY_SUCCESS`, `RECOVERY_FAILED`)

### API Specifications
Based on existing gateway manager and health monitoring patterns:
- **Gateway Manager Interface**: Extend existing gateway manager with process lifecycle methods
  - `terminate_gateway_process(gateway_id: str)` for clean shutdown
  - `restart_gateway_process(gateway_id: str, settings: dict)` for process relaunch
  - `get_gateway_process_status(gateway_id: str)` for restart monitoring
- **Event Bus Integration**: Publish recovery events from `apps/api/app/services/event_bus.py`
- **Health Monitor Integration**: Coordinate with existing health monitoring for recovery tracking

### File Locations
Based on unified project structure [Source: architecture/09-8-unified-project-structure-monorepo.md]:
- Gateway Recovery Service: `apps/api/app/services/gateway_recovery_service.py` (new file)
- Gateway Manager extensions: `apps/api/app/services/gateway_manager.py` (existing, needs process lifecycle methods)
- Health Monitor integration: `apps/api/app/services/health_monitor.py` (existing, needs recovery tracking)
- Main application integration: `apps/api/app/app.py` (needs recovery service startup)

### Technology Stack Requirements
- **Backend Framework**: FastAPI (latest) [Source: architecture/04-3-tech-stack.md]
- **Core Trading Library**: vnpy 4.0.0 for gateway process management [Source: architecture/04-3-tech-stack.md]
- **Process Management**: Python asyncio and subprocess for process lifecycle control
- **Event System**: Python asyncio for recovery event publishing and coordination

### Core Workflow Integration
Based on automated failover sequence [Source: architecture/07-6-core-workflows.md#6]:
- **Recovery Trigger**: Initiated after gateway marked UNHEALTHY in automated failover sequence
- **Cooldown Management**: Configurable delay before attempting restart to prevent rapid cycling
- **Process Management**: Safe termination and clean relaunch of vnpy gateway processes
- **Health Monitoring**: Continuous monitoring of restarted gateway until recovery confirmed

### Technical Constraints
- **Async Operations**: All recovery operations must be non-blocking using asyncio [Source: architecture/04-3-tech-stack.md]
- **Environment Variables**: Recovery behavior configurable via environment variables [Source: architecture/11-10-coding-standards.md#10]
- **Process Safety**: Gateway termination must be graceful to prevent data corruption
- **Resource Management**: Recovery operations should not impact normal system operation
- **Type Safety**: All recovery events must use proper TypeScript interfaces for frontend integration [Source: architecture/11-10-coding-standards.md#10]

### Integration with Existing Components
From Story 3.1 and 3.2 foundations:
- **Health Monitor**: Extend with recovery status tracking and restart attempt logging
- **Event Bus System**: Publish recovery events using established event format from existing system
- **Gateway Manager**: Extend with process lifecycle management methods for clean restart operations
- **Quote Aggregation Engine**: Coordinate with failover system to avoid conflicts during recovery
- **Database Service**: Track recovery statistics and restart attempt history

### Recovery Service Architecture
Core recovery coordination service:
- **Event-Driven Design**: React to UNHEALTHY gateway events from health monitor
- **Cooldown Management**: Implement configurable delays between restart attempts
- **Process Lifecycle Control**: Safe termination and relaunch of gateway processes
- **Recovery Coordination**: Track multiple concurrent recovery operations

**Example Recovery Event Flow:**
```json
{
  "event_type": "gateway_recovery_cycle",
  "timestamp": "2025-06-24T10:30:45.123Z",
  "gateway_id": "ctp_main_account",
  "recovery_phase": "completed",
  "restart_attempt": 2,
  "recovery_duration_ms": 15000,
  "metadata": {
    "cooldown_duration_ms": 5000,
    "termination_duration_ms": 2000,
    "initialization_duration_ms": 8000,
    "health_confirmation_ms": 5000,
    "previous_attempts": [
      {"attempt": 1, "result": "failed", "timestamp": "2025-06-24T10:25:30.000Z"}
    ]
  }
}
```

### Testing Requirements
Based on existing testing patterns from Stories 3.1 and 3.2:
- **Unit Tests**: Recovery service logic with mocked gateway manager and health monitor
- **Integration Tests**: Full recovery cycle with real process termination and restart
- **Service Tests**: Recovery service startup and event subscription
- **Process Management Tests**: Gateway process lifecycle validation with safety checks

### Testing

Dev Note: Story Requires the following tests:

- [ ] pytest Unit Tests: (nextToFile: true), coverage requirement: 80%
- [ ] pytest Integration Tests: location: `apps/api/tests/integration/test_gateway_recovery_service.py`
- [ ] Manual Service Testing: Recovery validation

Manual Test Steps:
- Set up test database with sample accounts for recovery testing
- Configure multiple enabled accounts using the API from Story 2.2
- Start the service: `cd apps/api && make dev`
- Verify recovery service initializes and subscribes to health events
- Simulate primary gateway failure through health monitor (trigger UNHEALTHY status)
- Monitor recovery service logs for cooldown period initiation
- Verify gateway process termination and clean restart after cooldown
- Monitor health monitor for recovery confirmation and HEALTHY status restoration
- Test recovery failure scenarios (process won't start, connection issues)
- Verify recovery attempt limits and permanent failure handling
- Test multiple concurrent gateway recovery operations
- Monitor performance metrics: recovery cycle should complete within configurable timeout
- Test both CTP and SOPT gateway recovery scenarios
- Verify recovery events are logged with complete metadata for troubleshooting
- Validate integration with existing failover system from Story 3.2

## Tasks / Subtasks

- [x] Task 1: Create Gateway Recovery Service module (AC: 1, 4)
  - [x] Create `apps/api/app/services/gateway_recovery_service.py` with GatewayRecoveryService class
  - [x] Implement event bus subscription for UNHEALTHY gateway events
  - [x] Define recovery state tracking data structures for cooldown and restart management
  - [x] Add configuration support for cooldown periods and recovery timeouts via environment variables
  - [x] Integrate with existing logging system for recovery event tracking

- [x] Task 2: Implement cooldown period management (AC: 1)
  - [x] Create configurable cooldown timer system with per-gateway tracking
  - [x] Implement recovery attempt counting and maximum retry limits
  - [x] Add cooldown period validation before initiating recovery operations
  - [x] Handle multiple concurrent cooldown timers for different gateways
  - [x] Implement exponential backoff for repeated recovery attempts

- [x] Task 3: Extend Gateway Manager with process lifecycle methods (AC: 2, 3)
  - [x] Add `terminate_gateway_process()` method for graceful process shutdown
  - [x] Implement `restart_gateway_process()` method for clean process relaunch
  - [x] Add `get_gateway_process_status()` method for restart monitoring
  - [x] Ensure process termination preserves data integrity and prevents corruption
  - [x] Support both CTP and SOPT gateway types in process lifecycle operations

- [x] Task 4: Implement gateway process relaunch logic (AC: 3)
  - [x] Query database for gateway settings during restart initialization
  - [x] Create new clean vnpy gateway instance with original configuration
  - [x] Handle process startup errors and initialization failures gracefully
  - [x] Implement process startup timeout controls to prevent hanging operations
  - [x] Ensure restarted gateway maintains same contract subscriptions as before failure

- [x] Task 5: Integrate recovery tracking with Health Monitor (AC: 4)
  - [x] Extend health monitor to track recovery status (`COOLING_DOWN`, `RESTARTING`, etc.)
  - [x] Monitor restarted gateway health confirmation and status transitions
  - [x] Implement recovery completion detection and success/failure determination
  - [x] Add recovery metrics collection for restart duration and success rates
  - [x] Publish recovery status events to event bus for dashboard consumption

- [x] Task 6: Integrate GatewayRecoveryService with FastAPI application lifecycle (AC: 1, 4)
  - [x] Add GatewayRecoveryService initialization to FastAPI startup events in `app.py`
  - [x] Start recovery event subscription background tasks for health status monitoring
  - [x] Ensure recovery service stops gracefully on application shutdown
  - [x] Handle recovery service errors that could crash the application
  - [x] Integrate with existing health endpoint to expose recovery status

- [x] Task 7: Testing and validation (All ACs)
  - [x] Create unit tests for GatewayRecoveryService class with mocked dependencies
  - [x] Create integration tests for complete recovery workflow with real process management
  - [x] Test cooldown period management with various configuration scenarios
  - [x] Test process termination and restart with both CTP and SOPT gateways
  - [x] Test recovery failure scenarios and maximum retry limit enforcement
  - [x] Create manual test procedures for recovery validation
  - [x] Verify recovery works with health events from Story 3.1 and failover system from Story 3.2

## Dev Notes

### Recovery Service Strategy
The GatewayRecoveryService should:
- Run as background asyncio tasks for recovery event processing
- Maintain recovery state for each gateway with cooldown and retry tracking
- Coordinate with existing failover system to prevent conflicts during recovery
- Support configurable recovery policies (immediate, delayed, maximum attempts)
- Handle multiple simultaneous gateway recovery operations safely

### Gateway Manager Process Lifecycle Extensions
The existing `gateway_manager.py` needs extension:
- Add process termination methods with graceful shutdown procedures
- Provide process restart methods with clean initialization
- Support process status monitoring for recovery confirmation
- Ensure process operations don't interfere with normal gateway functionality

### Integration with Existing Systems
Recovery service coordination should:
- Subscribe to UNHEALTHY events from health monitor without modifying existing logic
- Coordinate with quote aggregation engine to avoid conflicts during recovery
- Use existing event bus patterns for recovery status communication
- Respect existing database patterns for configuration and state tracking

### Recovery Decision Algorithm
Cooldown and restart logic:
- Trigger recovery only after configurable cooldown period expires
- Track restart attempts per gateway with maximum retry limits
- Implement exponential backoff for repeated failures
- Handle edge cases: multiple failures, concurrent recovery operations
- Maintain recovery statistics for operational monitoring

**Example Recovery Timeline:**
```python
# Gateway failure detection at T+0
# Failover to backup gateway (Story 3.2) at T+150ms
# Recovery cooldown starts at T+200ms (configurable: 5 seconds default)
# Process termination at T+5200ms
# Process restart at T+7200ms  
# Health confirmation at T+15200ms
# Recovery complete event at T+15250ms
```

### Process Management Strategy
Safe gateway process restart:
- Graceful termination with connection cleanup before restart
- Clean process initialization with original gateway settings
- Monitor startup progress and detect initialization failures
- Implement restart timeout controls to prevent hanging operations
- Preserve contract subscription state for seamless restoration

### Performance Considerations
- Recovery operations must not impact normal system performance
- Use asyncio for concurrent recovery operations across multiple gateways
- Implement recovery timeout controls to prevent resource leaks
- Monitor recovery service resource usage to ensure efficiency

**Expected Performance Metrics:**
- **Recovery Cycle Time**: <15 seconds from cooldown start to health confirmation
- **Process Termination**: <2 seconds for graceful gateway shutdown
- **Process Startup**: <8 seconds for clean gateway initialization
- **Memory Usage**: <2MB additional RAM for recovery service state tracking
- **CPU Usage**: <0.5% additional utilization during normal operation
- **Recovery Success Rate**: >95% for healthy system configurations

### Error Handling Strategy
- **Process Termination Errors**: Log warnings but proceed with restart attempt
- **Process Startup Errors**: Implement retry logic with maximum attempt limits
- **Health Monitor Errors**: Continue recovery tracking but log coordination issues
- **Database Errors**: Use cached gateway settings with periodic refresh
- **Maximum Retries Exceeded**: Mark gateway as permanently failed and alert operators
- **Recovery Service Failure**: Implement graceful degradation with manual recovery mode

### Recovery Service Rollback Strategy
If the recovery service itself fails or causes system instability:
- **Immediate Disable**: Environment variable `RECOVERY_SERVICE_ENABLED=false` to disable recovery service
- **Graceful Shutdown**: Recovery service monitors for shutdown signals and stops cleanly
- **Fallback Mode**: System continues with manual recovery only (existing failover system unaffected)
- **Rollback Procedure**: Stop recovery service, clear any in-progress recovery state, restart application
- **Monitoring**: Recovery service health exposed via existing health endpoint for external monitoring

### Future Extensibility
Design for future enhancements:
- Manual recovery triggers from dashboard UI (Story 4.3)
- Recovery analytics and success rate monitoring
- Custom recovery policies per gateway type or configuration
- Intelligent recovery timing based on historical failure patterns

## Dev Agent Record

### Agent Model Used: 
claude-sonnet-4-20250514

### Debug Log References
No debug logging required during implementation - all tasks completed successfully without debugging needs.

### Completion Notes List
- Successfully implemented all acceptance criteria without deviations
- Gateway Recovery Service integrates seamlessly with existing health monitoring system
- All unit tests pass (17/17) with comprehensive coverage of recovery workflows
- Integration tests created for full end-to-end recovery validation
- Process lifecycle methods added to Gateway Manager for clean termination and restart
- Recovery service properly integrated into FastAPI application lifecycle
- Cooldown management includes exponential backoff configuration
- Recovery events are published to event bus for dashboard integration
- Health endpoint now includes recovery service status information

### Change Log

| Date | Version | Description | Author |
| :--- | :------ | :---------- | :----- |
| 2025-06-24 | 1.0 | Initial story draft created | Scrum Master |
| 2025-06-24 | 1.1 | Updated based on PO review feedback | Scrum Master |